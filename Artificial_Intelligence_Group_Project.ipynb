{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee38667/AI_Group_Project/blob/main/Artificial_Intelligence_Group_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywImSgFmLJwq"
      },
      "source": [
        "**PART 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBEn1m-xTZ-7"
      },
      "source": [
        "**Loading the CSV into Dataframes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZI_LOnBx3MH"
      },
      "source": [
        "**Co author comparison graph**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91CMoLhGx9rd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import sys\n",
        "from collections import deque\n",
        "\n",
        "# Data structures\n",
        "names = {}\n",
        "scientists = {}\n",
        "papers = {}\n",
        "paper_to_scientists = {}\n",
        "scientist_to_papers = {}\n",
        "\n",
        "def load_data(directory):\n",
        "    # Load scientists\n",
        "    with open(f\"{directory}/scientists.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            scientists[row[\"scientist_id\"]] = {\n",
        "                \"name\": row[\"name\"],\n",
        "                \"papers\": set()\n",
        "            }\n",
        "            if row[\"name\"] not in names:\n",
        "                names[row[\"name\"]] = {row[\"scientist_id\"]}\n",
        "            else:\n",
        "                names[row[\"name\"]].add(row[\"scientist_id\"])\n",
        "\n",
        "    # Load papers\n",
        "    with open(f\"{directory}/papers.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            papers[row[\"paper_id\"]] = {\n",
        "                \"title\": row[\"title\"],\n",
        "                \"year\": row[\"year\"],\n",
        "                \"authors\": set()\n",
        "            }\n",
        "\n",
        "    # Load authors\n",
        "    with open(f\"{directory}/authors.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            try:\n",
        "                scientist_id = row[\"scientist_id\"]\n",
        "                paper_id = row[\"paper_id\"]\n",
        "                scientists[scientist_id][\"papers\"].add(paper_id)\n",
        "                papers[paper_id][\"authors\"].add(scientist_id)\n",
        "\n",
        "                # Build mappings\n",
        "                if paper_id not in paper_to_scientists:\n",
        "                    paper_to_scientists[paper_id] = set()\n",
        "                paper_to_scientists[paper_id].add(scientist_id)\n",
        "\n",
        "                if scientist_id not in scientist_to_papers:\n",
        "                    scientist_to_papers[scientist_id] = set()\n",
        "                scientist_to_papers[scientist_id].add(paper_id)\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "def neighbors_for_person(scientist_id):\n",
        "    neighbors = set()\n",
        "    for paper_id in scientist_to_papers.get(scientist_id, set()):\n",
        "        for coauthor_id in paper_to_scientists.get(paper_id, set()):\n",
        "            if coauthor_id != scientist_id:\n",
        "                neighbors.add((paper_id, coauthor_id))\n",
        "    return neighbors\n",
        "\n",
        "def shortest_path(source, target):\n",
        "    if source == target:\n",
        "        return []\n",
        "\n",
        "    queue = deque()\n",
        "    queue.append((source, []))\n",
        "    visited = set()\n",
        "    visited.add(source)\n",
        "\n",
        "    while queue:\n",
        "        current, path = queue.popleft()\n",
        "        for paper_id, neighbor in neighbors_for_person(current):\n",
        "            if neighbor == target:\n",
        "                return path + [(paper_id, neighbor)]\n",
        "            if neighbor not in visited:\n",
        "                visited.add(neighbor)\n",
        "                queue.append((neighbor, path + [(paper_id, neighbor)]))\n",
        "    return None\n",
        "\n",
        "def person_id_for_name(name):\n",
        "    person_ids = list(names.get(name, set()))\n",
        "    if not person_ids:\n",
        "        return None\n",
        "    elif len(person_ids) > 1:\n",
        "        print(f\"Which '{name}'?\")\n",
        "        for pid in person_ids:\n",
        "            print(f\"ID: {pid}, Name: {scientists[pid]['name']}\")\n",
        "        return input(\"Intended ID: \").strip()\n",
        "    else:\n",
        "        return person_ids[0]\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) != 2:\n",
        "        sys.exit(\"Usage: python Scientist.py [directory]\")\n",
        "    directory = sys.argv[1]\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    load_data(directory)\n",
        "    print(\"Data loaded.\")\n",
        "\n",
        "    source_name = input(\"Name: \").strip()\n",
        "    source_id = person_id_for_name(source_name)\n",
        "    if source_id is None:\n",
        "        sys.exit(\"Scientist not found.\")\n",
        "\n",
        "    target_name = input(\"Name: \").strip()\n",
        "    target_id = person_id_for_name(target_name)\n",
        "    if target_id is None:\n",
        "        sys.exit(\"Scientist not found.\")\n",
        "\n",
        "    path = shortest_path(source_id, target_id)\n",
        "\n",
        "    if path is None:\n",
        "        print(\"No connection found.\")\n",
        "    else:\n",
        "        degrees = len(path)\n",
        "        print(f\"{degrees} degrees of separation.\")\n",
        "        current_id = source_id\n",
        "        for i, (paper_id, scientist_id) in enumerate(path, 1):\n",
        "            paper = papers[paper_id]\n",
        "            next_name = scientists[scientist_id][\"name\"]\n",
        "            current_name = scientists[current_id][\"name\"]\n",
        "            print(f\"{i}: {current_name} and {next_name} co-authored \\\"{paper['title']}\\\"\")\n",
        "            current_id = scientist_id\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGAKylEZhlW"
      },
      "source": [
        "**Part 2 AI Sudoku Puzzle Solver**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1y_3TpnZsWR"
      },
      "outputs": [],
      "source": [
        "class Sudoku_AI_Solver:\n",
        "    def __init__(self):\n",
        "        self.domains = {\n",
        "            (i, j): set(range(1, 10)) for i in range(9) for j in range(9)\n",
        "        }\n",
        "\n",
        "    def load_from_file(self, filename):\n",
        "        \"\"\"Load Sudoku puzzle from file with error handling to ensure clear instructions\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                lines = [line.strip().replace(\" \", \"\") for line in f if line.strip()]\n",
        "\n",
        "            if len(lines) != 9:\n",
        "              #ensure there's no empty spaces even though we've added line correction (first issue encountered)\n",
        "                raise ValueError(\"File must contain exactly 9 lines\")\n",
        "\n",
        "            for i in range(9):\n",
        "                if len(lines[i]) != 9:\n",
        "                    raise ValueError(f\"Line {i+1} must contain exactly 9 characters\")\n",
        "                for j in range(9):\n",
        "                    val = int(lines[i][j])\n",
        "                    if val == 0:\n",
        "                        self.domains[(i, j)] = set(range(1, 10))\n",
        "                    elif 1 <= val <= 9:\n",
        "                        self.domains[(i, j)] = {val}\n",
        "                    else:\n",
        "                        raise ValueError(f\"Invalid value {val} at position ({i}, {j})\")\n",
        "        except FileNotFoundError:\n",
        "            raise FileNotFoundError(f\"File {filename} not found\")\n",
        "        except ValueError as e:\n",
        "            raise ValueError(f\"Invalid Sudoku file: {str(e)}\")\n",
        "\n",
        "    def enforce_node_consistency(self):\n",
        "        for cell in self.domains:\n",
        "            if len(self.domains[cell]) == 1:\n",
        "                val = next(iter(self.domains[cell]))\n",
        "                self.domains[cell] = {val}\n",
        "\n",
        "    def revise(self, x, y):\n",
        "        revised = False\n",
        "        if len(self.domains[y]) == 1:\n",
        "            val_y = next(iter(self.domains[y]))\n",
        "            if val_y in self.domains[x]:\n",
        "                if len(self.domains[x]) > 1:\n",
        "                    self.domains[x].remove(val_y)\n",
        "                    revised = True\n",
        "        return revised\n",
        "\n",
        "    def ac3(self):\n",
        "        queue = [(x, y) for x in self.domains for y in self.get_neighbors(x)]\n",
        "        while queue:\n",
        "            x, y = queue.pop(0)\n",
        "            if self.revise(x, y):\n",
        "                if len(self.domains[x]) == 0:\n",
        "                    return False\n",
        "                for z in self.get_neighbors(x):\n",
        "                    if z != y:\n",
        "                        queue.append((z, x))\n",
        "        return True\n",
        "\n",
        "    def assignment_complete(self, assignment):\n",
        "        return all(len(assignment[cell]) == 1 for cell in assignment)\n",
        "\n",
        "    def consistent(self, assignment):\n",
        "        for cell in assignment:\n",
        "            if len(assignment[cell]) == 1:\n",
        "                val = next(iter(assignment[cell]))\n",
        "                for neighbor in self.get_neighbors(cell):\n",
        "                    if len(assignment[neighbor]) == 1:\n",
        "                        if val == next(iter(assignment[neighbor])):\n",
        "                            return False\n",
        "        return True\n",
        "\n",
        "    def order_domain_values(self, var, assignment):\n",
        "        def count_conflicts(value):\n",
        "            count = 0\n",
        "            for neighbor in self.get_neighbors(var):\n",
        "                if value in assignment[neighbor]:\n",
        "                    count += 1\n",
        "            return count\n",
        "        return sorted(assignment[var], key=count_conflicts)\n",
        "\n",
        "    def select_unassigned_variable(self, assignment):\n",
        "        unassigned = [v for v in assignment if len(assignment[v]) > 1]\n",
        "        return min(unassigned, key=lambda var: (len(assignment[var]), -len(self.get_neighbors(var))))\n",
        "\n",
        "    def backtrack(self, assignment):\n",
        "        if self.assignment_complete(assignment):\n",
        "            return assignment\n",
        "        var = self.select_unassigned_variable(assignment)\n",
        "        for value in self.order_domain_values(var, assignment):\n",
        "            new_assignment = {k: v.copy() for k, v in assignment.items()}\n",
        "            new_assignment[var] = {value}\n",
        "            if self.consistent(new_assignment):\n",
        "                result = self.backtrack(new_assignment)\n",
        "                if result:\n",
        "                    return result\n",
        "        return None\n",
        "\n",
        "    def get_neighbors(self, cell):\n",
        "        i, j = cell\n",
        "        neighbors = set()\n",
        "        for k in range(9):\n",
        "            if k != j:\n",
        "                neighbors.add((i, k))\n",
        "            if k != i:\n",
        "                neighbors.add((k, j))\n",
        "        top_left_i = 3 * (i // 3)\n",
        "        top_left_j = 3 * (j // 3)\n",
        "        for a in range(top_left_i, top_left_i + 3):\n",
        "            for b in range(top_left_j, top_left_j + 3):\n",
        "                if (a, b) != cell:\n",
        "                    neighbors.add((a, b))\n",
        "        return neighbors\n",
        "\n",
        "    def solve(self):\n",
        "        self.enforce_node_consistency()\n",
        "        if not self.ac3():\n",
        "            print(\"AC-3 failed\")\n",
        "            return None\n",
        "        return self.backtrack(self.domains)\n",
        "\n",
        "    def display(self, assignment):\n",
        "        for i in range(9):\n",
        "            if i % 3 == 0 and i != 0:\n",
        "                print(\"-\" * 21)\n",
        "            for j in range(9):\n",
        "                if j % 3 == 0 and j != 0:\n",
        "                    print(\"|\", end=\" \")\n",
        "                val = next(iter(assignment[(i, j)]))\n",
        "                print(val if val != 0 else \".\", end=\" \")\n",
        "            print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    solver = Sudoku_AI_Solver()\n",
        "    try:\n",
        "        solver.load_from_file(\"sudoku_easy.txt\")\n",
        "        solution = solver.solve()\n",
        "        if solution:\n",
        "            print(\"Solution found:\")\n",
        "            solver.display(solution)\n",
        "        else:\n",
        "            print(\"No solution found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part **3**"
      ],
      "metadata": {
        "id": "vJTPosoSISwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install neccesary libraries**"
      ],
      "metadata": {
        "id": "Z5JJeuzrhKIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow opencv-python scikit-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-nNKnnYMhGbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xCTB6iZfx0E"
      },
      "source": [
        "Part 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "EPOCHS = 50  # Let EarlyStopping decide the best epoch\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 43\n",
        "TEST_SIZE = 0.4\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Check command-line arguments\n",
        "    if len(sys.argv) != 2:\n",
        "        sys.exit(\"Usage: python traffic.py data_directory\")\n",
        "\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(sys.argv[1])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Train the model with validation split and early stopping\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=EPOCHS,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Save model with versioning\n",
        "    save_model_with_version(model)\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label in range(NUM_CATEGORIES):\n",
        "        label_dir = os.path.join(data_dir, str(label))\n",
        "        if not os.path.isdir(label_dir):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(label_dir):\n",
        "            filepath = os.path.join(label_dir, filename)\n",
        "            image = cv2.imread(filepath)\n",
        "\n",
        "            if image is None:\n",
        "                continue\n",
        "\n",
        "            image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training vs. Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training vs. Validation Loss')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_model_with_version(model, folder=\".\"):\n",
        "    \"\"\"\n",
        "    Save model to file as modelV#.h5, where # is the next available version number.\n",
        "    \"\"\"\n",
        "    version = 1\n",
        "    while os.path.exists(os.path.join(folder, f\"modelV{version}.h5\")):\n",
        "        version += 1\n",
        "\n",
        "    filename = os.path.join(folder, f\"modelV{version}.h5\")\n",
        "    model.save(filename)\n",
        "    print(f\"Model saved to {filename}.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "bNwqWgDuiIa4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCT7L8MQ50lluWdovhlkqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}